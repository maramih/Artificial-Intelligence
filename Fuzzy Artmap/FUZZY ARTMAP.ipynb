{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epsilon = 0.001\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.minimum([0,1,1,0],[0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            splittedLine = line.split(\" \")\n",
    "            X = splittedLine[:256]\n",
    "            X = np.array([0 if float(i) == 0. else 1 for i in X])\n",
    "            X_data.append(X)\n",
    "\n",
    "            y = splittedLine[256:-1]\n",
    "            y = [int(i) for i in y]\n",
    "            y = y.index(1)\n",
    "            y_data.append(y)\n",
    "\n",
    "    return np.array(X_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(a, b):\n",
    "    pos = np.random.permutation(len(a))\n",
    "    return a[pos], b[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addComplement(X):\n",
    "    X_data = []\n",
    "    for x in X:\n",
    "        complement = np.array([i ^ 1 for i in x])\n",
    "        X_data.append(np.concatenate((x, complement), axis=None))\n",
    "\n",
    "    return np.array(X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_T(I, w, alpha):\n",
    "    T = np.sum(np.minimum(I, w)) / (alpha + np.sum(w))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNeuron(layer, n):\n",
    "    w = np.ones(n)\n",
    "    layer.append([w, 0, -1])  # weights,committed/uncommitted, class label\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X, y, alpha, beta, vigilance):\n",
    "    second_layer = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for it in range(X.shape[0]):\n",
    "            if len(second_layer) == 0:\n",
    "                second_layer = addNeuron(second_layer, X.shape[1])\n",
    "\n",
    "            T = []\n",
    "            step = 1\n",
    "            J = -1\n",
    "            l_vigilance = -1\n",
    "            while True:\n",
    "                if step == 1:\n",
    "                    print('1----set the vigilance factor equal to its baseline value')\n",
    "                    l_vigilance = vigilance\n",
    "                    step = 2\n",
    "                    \n",
    "               \n",
    "                if step == 2:\n",
    "                    print('2---insert input and calculate second layers activities')\n",
    "                    for i in range(len(second_layer)):\n",
    "                        if second_layer[i][1] == 0:\n",
    "                            t = np.random.random()\n",
    "                            print(\"if\",t)\n",
    "                        else:\n",
    "                            t = calculate_T(X[it], second_layer[i][0], alpha)\n",
    "                            print(\"else\", t)\n",
    "                        T.append(t)\n",
    "\n",
    "                    step = 3\n",
    "                \n",
    "               \n",
    "                if step == 3: \n",
    "                    print('3----find the winner neuron')\n",
    "                    J = np.argmax(T)\n",
    "                    \n",
    "                    print(J)\n",
    "                    print('3.2----check if the neuron is commited')\n",
    "                    if second_layer[J][1] == 0: \n",
    "                        step = 7\n",
    "                    else:\n",
    "                        step = 4\n",
    "                \n",
    "                if step == 4:\n",
    "                    print('4----check vigilance to see if the input is similar enough to the winner s prototype')\n",
    "                    if np.sum(np.minimum(X[it], second_layer[J][0])) / np.sum(X[it]) >= l_vigilance:\n",
    "                        step = 5\n",
    "                    else: \n",
    "                        print('4else-----check next winner')\n",
    "                        T[J] = -1\n",
    "                        step = 3\n",
    "                \n",
    "                \n",
    "                if step == 5:\n",
    "                    print('5----check if winner class label matches with the input class label')\n",
    "                    if second_layer[J][2] == y[it]:\n",
    "                        w_new = beta * np.minimum(X[it], second_layer[J][0]) + (1 - beta) * second_layer[J][0]\n",
    "                        second_layer[J][0] = w_new\n",
    "                        step = 9\n",
    "                    else: \n",
    "                        T[J] = -1\n",
    "                        l_vigilance = np.sum(np.minimum(X[it], second_layer[J][0])) / np.sum(X[it]) + epsilon\n",
    "                        step = 6\n",
    "                \n",
    "                if step == 6:\n",
    "                    print('6---#check if vigilance to terminate the training in the current epoch ')\n",
    "                    if l_vigilance > 1:\n",
    "                        step = 9\n",
    "                    else:\n",
    "                        step = 3\n",
    "               \n",
    "                if step == 7:\n",
    "                    print('7--create new subclass')\n",
    "                    second_layer[J][0] = X[it]\n",
    "                    second_layer[J][1] = 1\n",
    "                    second_layer[J][2] = y[it]\n",
    "                    step = 8\n",
    "                \n",
    "                \n",
    "                if step == 8:\n",
    "                    print('8--create a new uncommitted neuron')\n",
    "                    second_layer = addNeuron(second_layer, X.shape[1])\n",
    "                    step = 9\n",
    "                \n",
    "               \n",
    "                if step == 9:\n",
    "                    print()\n",
    "                    print(second_layer)\n",
    "                    print()\n",
    "                    print(T)\n",
    "                    print('neeeext')\n",
    "                    print()\n",
    "                    break\n",
    "\n",
    "    return second_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1----set the vigilance factor equal to its baseline value\n",
      "2---insert input and calculate second layers activities\n",
      "if 0.8721342190296142\n",
      "3----find the winner neuron\n",
      "0\n",
      "3.2----check if the neuron is commited\n",
      "7--create new subclass\n",
      "8--create a new uncommitted neuron\n",
      "\n",
      "[[array([0, 0, 1, 1]), 1, 0], [array([1., 1., 1., 1.]), 0, -1]]\n",
      "\n",
      "[0.8721342190296142]\n",
      "neeeext\n",
      "\n",
      "1----set the vigilance factor equal to its baseline value\n",
      "2---insert input and calculate second layers activities\n",
      "else 0.3333333333333333\n",
      "if 0.929184598576625\n",
      "3----find the winner neuron\n",
      "1\n",
      "3.2----check if the neuron is commited\n",
      "7--create new subclass\n",
      "8--create a new uncommitted neuron\n",
      "\n",
      "[[array([0, 0, 1, 1]), 1, 0], [array([0, 1, 1, 0]), 1, 1], [array([1., 1., 1., 1.]), 0, -1]]\n",
      "\n",
      "[0.3333333333333333, 0.929184598576625]\n",
      "neeeext\n",
      "\n",
      "1----set the vigilance factor equal to its baseline value\n",
      "2---insert input and calculate second layers activities\n",
      "else 0.3333333333333333\n",
      "else 0.0\n",
      "if 0.9116673628183717\n",
      "3----find the winner neuron\n",
      "2\n",
      "3.2----check if the neuron is commited\n",
      "7--create new subclass\n",
      "8--create a new uncommitted neuron\n",
      "\n",
      "[[array([0, 0, 1, 1]), 1, 0], [array([0, 1, 1, 0]), 1, 1], [array([1, 0, 0, 1]), 1, 1], [array([1., 1., 1., 1.]), 0, -1]]\n",
      "\n",
      "[0.3333333333333333, 0.0, 0.9116673628183717]\n",
      "neeeext\n",
      "\n",
      "1----set the vigilance factor equal to its baseline value\n",
      "2---insert input and calculate second layers activities\n",
      "else 0.0\n",
      "else 0.3333333333333333\n",
      "else 0.3333333333333333\n",
      "if 0.708856479729293\n",
      "3----find the winner neuron\n",
      "3\n",
      "3.2----check if the neuron is commited\n",
      "7--create new subclass\n",
      "8--create a new uncommitted neuron\n",
      "\n",
      "[[array([0, 0, 1, 1]), 1, 0], [array([0, 1, 1, 0]), 1, 1], [array([1, 0, 0, 1]), 1, 1], [array([1, 1, 0, 0]), 1, 0], [array([1., 1., 1., 1.]), 0, -1]]\n",
      "\n",
      "[0.0, 0.3333333333333333, 0.3333333333333333, 0.708856479729293]\n",
      "neeeext\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([0,1,1,0])\n",
    "alpha=beta=1\n",
    "vigilance=0.5\n",
    "X=addComplement(X)\n",
    "aux=run(X, y, alpha, beta, vigilance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0, 0, 1, 1]), 1, 0],\n",
       " [array([0, 1, 1, 0]), 1, 1],\n",
       " [array([1, 0, 0, 1]), 1, 1],\n",
       " [array([1, 1, 0, 0]), 1, 0],\n",
       " [array([1., 1., 1., 1.]), 0, -1]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(second_layer, X, y, alpha):\n",
    "    nr = 0\n",
    "    for it in range(X.shape[0]):\n",
    "        T = []\n",
    "        for i in range(len(second_layer)):\n",
    "            t = calculate_T(X[it], second_layer[i][0], alpha)\n",
    "            T.append(t)\n",
    "\n",
    "        J = np.argmax(T)\n",
    "        if second_layer[J][2] == y[it]:\n",
    "            nr += 1\n",
    "\n",
    "    return 100 * nr / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(aux,X,y,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(\"semeion.data\");\n",
    "X, y = shuffle(X, y)\n",
    "X = addComplement(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_train = int(70 * X.shape[0] / 100)\n",
    "X_train = X[:nr_train, :]\n",
    "y_train = y[:nr_train]\n",
    "X_test = X[nr_train:, :]\n",
    "y_test = y[nr_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_train_train = int(70 * X_train.shape[0] / 100)\n",
    "X_train_train = X_train[:nr_train_train, :]\n",
    "X_train_valid = X_train[nr_train_train:, :]\n",
    "y_train_train = y_train[:nr_train_train]\n",
    "y_train_valid = y_train[nr_train_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.01, 0.1, 0.2, 0.3, 0.4]\n",
    "beta = [1, 0.8, 0.6, 0.4]\n",
    "vigilance = [0.01, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = -1\n",
    "best_beta = -1\n",
    "best_vigilance = -1\n",
    "maximum_accuracy = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: alpha= 0.01, beta= 1, vigilance= 0.01\n",
      "Accuracy train validation= 75.22388059701493\n",
      "Param: alpha= 0.01, beta= 1, vigilance= 0.1\n",
      "Accuracy train validation= 78.2089552238806\n",
      "Param: alpha= 0.01, beta= 1, vigilance= 0.2\n",
      "Accuracy train validation= 80.8955223880597\n",
      "Param: alpha= 0.01, beta= 1, vigilance= 0.3\n",
      "Accuracy train validation= 88.95522388059702\n",
      "Param: alpha= 0.01, beta= 0.8, vigilance= 0.01\n",
      "Accuracy train validation= 73.13432835820896\n",
      "Param: alpha= 0.01, beta= 0.8, vigilance= 0.1\n",
      "Accuracy train validation= 76.41791044776119\n",
      "Param: alpha= 0.01, beta= 0.8, vigilance= 0.2\n",
      "Accuracy train validation= 87.16417910447761\n",
      "Param: alpha= 0.01, beta= 0.8, vigilance= 0.3\n",
      "Accuracy train validation= 87.16417910447761\n",
      "Param: alpha= 0.01, beta= 0.6, vigilance= 0.01\n",
      "Accuracy train validation= 75.22388059701493\n",
      "Param: alpha= 0.01, beta= 0.6, vigilance= 0.1\n",
      "Accuracy train validation= 80.59701492537313\n",
      "Param: alpha= 0.01, beta= 0.6, vigilance= 0.2\n",
      "Accuracy train validation= 82.98507462686567\n",
      "Param: alpha= 0.01, beta= 0.6, vigilance= 0.3\n",
      "Accuracy train validation= 87.16417910447761\n",
      "Param: alpha= 0.01, beta= 0.4, vigilance= 0.01\n",
      "Accuracy train validation= 79.40298507462687\n",
      "Param: alpha= 0.01, beta= 0.4, vigilance= 0.1\n",
      "Accuracy train validation= 78.2089552238806\n",
      "Param: alpha= 0.01, beta= 0.4, vigilance= 0.2\n",
      "Accuracy train validation= 77.61194029850746\n",
      "Param: alpha= 0.01, beta= 0.4, vigilance= 0.3\n",
      "Accuracy train validation= 82.68656716417911\n",
      "Param: alpha= 0.1, beta= 1, vigilance= 0.01\n",
      "Accuracy train validation= 72.53731343283582\n",
      "Param: alpha= 0.1, beta= 1, vigilance= 0.1\n",
      "Accuracy train validation= 77.01492537313433\n",
      "Param: alpha= 0.1, beta= 1, vigilance= 0.2\n",
      "Accuracy train validation= 80.0\n",
      "Param: alpha= 0.1, beta= 1, vigilance= 0.3\n",
      "Accuracy train validation= 88.05970149253731\n",
      "Param: alpha= 0.1, beta= 0.8, vigilance= 0.01\n",
      "Accuracy train validation= 72.83582089552239\n",
      "Param: alpha= 0.1, beta= 0.8, vigilance= 0.1\n",
      "Accuracy train validation= 79.40298507462687\n",
      "Param: alpha= 0.1, beta= 0.8, vigilance= 0.2\n",
      "Accuracy train validation= 85.3731343283582\n",
      "Param: alpha= 0.1, beta= 0.8, vigilance= 0.3\n",
      "Accuracy train validation= 87.46268656716418\n",
      "Param: alpha= 0.1, beta= 0.6, vigilance= 0.01\n",
      "Accuracy train validation= 74.92537313432835\n",
      "Param: alpha= 0.1, beta= 0.6, vigilance= 0.1\n",
      "Accuracy train validation= 80.59701492537313\n",
      "Param: alpha= 0.1, beta= 0.6, vigilance= 0.2\n",
      "Accuracy train validation= 83.28358208955224\n",
      "Param: alpha= 0.1, beta= 0.6, vigilance= 0.3\n",
      "Accuracy train validation= 86.86567164179104\n",
      "Param: alpha= 0.1, beta= 0.4, vigilance= 0.01\n",
      "Accuracy train validation= 80.8955223880597\n",
      "Param: alpha= 0.1, beta= 0.4, vigilance= 0.1\n",
      "Accuracy train validation= 79.70149253731343\n",
      "Param: alpha= 0.1, beta= 0.4, vigilance= 0.2\n",
      "Accuracy train validation= 82.68656716417911\n",
      "Param: alpha= 0.1, beta= 0.4, vigilance= 0.3\n",
      "Accuracy train validation= 82.68656716417911\n",
      "Param: alpha= 0.2, beta= 1, vigilance= 0.01\n",
      "Accuracy train validation= 74.92537313432835\n",
      "Param: alpha= 0.2, beta= 1, vigilance= 0.1\n",
      "Accuracy train validation= 76.11940298507463\n",
      "Param: alpha= 0.2, beta= 1, vigilance= 0.2\n",
      "Accuracy train validation= 85.07462686567165\n",
      "Param: alpha= 0.2, beta= 1, vigilance= 0.3\n",
      "Accuracy train validation= 88.05970149253731\n",
      "Param: alpha= 0.2, beta= 0.8, vigilance= 0.01\n",
      "Accuracy train validation= 75.5223880597015\n",
      "Param: alpha= 0.2, beta= 0.8, vigilance= 0.1\n",
      "Accuracy train validation= 80.0\n",
      "Param: alpha= 0.2, beta= 0.8, vigilance= 0.2\n",
      "Accuracy train validation= 81.7910447761194\n",
      "Param: alpha= 0.2, beta= 0.8, vigilance= 0.3\n",
      "Accuracy train validation= 87.46268656716418\n",
      "Param: alpha= 0.2, beta= 0.6, vigilance= 0.01\n",
      "Accuracy train validation= 78.80597014925372\n",
      "Param: alpha= 0.2, beta= 0.6, vigilance= 0.1\n",
      "Accuracy train validation= 78.80597014925372\n",
      "Param: alpha= 0.2, beta= 0.6, vigilance= 0.2\n",
      "Accuracy train validation= 83.88059701492537\n",
      "Param: alpha= 0.2, beta= 0.6, vigilance= 0.3\n",
      "Accuracy train validation= 87.16417910447761\n",
      "Param: alpha= 0.2, beta= 0.4, vigilance= 0.01\n",
      "Accuracy train validation= 76.11940298507463\n",
      "Param: alpha= 0.2, beta= 0.4, vigilance= 0.1\n",
      "Accuracy train validation= 81.19402985074628\n",
      "Param: alpha= 0.2, beta= 0.4, vigilance= 0.2\n",
      "Accuracy train validation= 80.29850746268657\n",
      "Param: alpha= 0.2, beta= 0.4, vigilance= 0.3\n",
      "Accuracy train validation= 82.38805970149254\n",
      "Param: alpha= 0.3, beta= 1, vigilance= 0.01\n",
      "Accuracy train validation= 71.64179104477611\n",
      "Param: alpha= 0.3, beta= 1, vigilance= 0.1\n",
      "Accuracy train validation= 76.41791044776119\n",
      "Param: alpha= 0.3, beta= 1, vigilance= 0.2\n",
      "Accuracy train validation= 82.38805970149254\n",
      "Param: alpha= 0.3, beta= 1, vigilance= 0.3\n",
      "Accuracy train validation= 88.35820895522389\n",
      "Param: alpha= 0.3, beta= 0.8, vigilance= 0.01\n",
      "Accuracy train validation= 81.7910447761194\n",
      "Param: alpha= 0.3, beta= 0.8, vigilance= 0.1\n",
      "Accuracy train validation= 80.8955223880597\n",
      "Param: alpha= 0.3, beta= 0.8, vigilance= 0.2\n",
      "Accuracy train validation= 83.58208955223881\n",
      "Param: alpha= 0.3, beta= 0.8, vigilance= 0.3\n",
      "Accuracy train validation= 86.26865671641791\n",
      "Param: alpha= 0.3, beta= 0.6, vigilance= 0.01\n",
      "Accuracy train validation= 79.40298507462687\n",
      "Param: alpha= 0.3, beta= 0.6, vigilance= 0.1\n",
      "Accuracy train validation= 81.7910447761194\n",
      "Param: alpha= 0.3, beta= 0.6, vigilance= 0.2\n",
      "Accuracy train validation= 83.88059701492537\n",
      "Param: alpha= 0.3, beta= 0.6, vigilance= 0.3\n",
      "Accuracy train validation= 82.98507462686567\n",
      "Param: alpha= 0.3, beta= 0.4, vigilance= 0.01\n",
      "Accuracy train validation= 78.2089552238806\n",
      "Param: alpha= 0.3, beta= 0.4, vigilance= 0.1\n",
      "Accuracy train validation= 79.40298507462687\n",
      "Param: alpha= 0.3, beta= 0.4, vigilance= 0.2\n",
      "Accuracy train validation= 82.38805970149254\n",
      "Param: alpha= 0.3, beta= 0.4, vigilance= 0.3\n",
      "Accuracy train validation= 83.58208955223881\n",
      "Param: alpha= 0.4, beta= 1, vigilance= 0.01\n",
      "Accuracy train validation= 73.73134328358209\n",
      "Param: alpha= 0.4, beta= 1, vigilance= 0.1\n",
      "Accuracy train validation= 76.41791044776119\n",
      "Param: alpha= 0.4, beta= 1, vigilance= 0.2\n",
      "Accuracy train validation= 82.38805970149254\n",
      "Param: alpha= 0.4, beta= 1, vigilance= 0.3\n",
      "Accuracy train validation= 88.95522388059702\n",
      "Param: alpha= 0.4, beta= 0.8, vigilance= 0.01\n",
      "Accuracy train validation= 77.61194029850746\n",
      "Param: alpha= 0.4, beta= 0.8, vigilance= 0.1\n",
      "Accuracy train validation= 78.50746268656717\n",
      "Param: alpha= 0.4, beta= 0.8, vigilance= 0.2\n",
      "Accuracy train validation= 81.49253731343283\n",
      "Param: alpha= 0.4, beta= 0.8, vigilance= 0.3\n",
      "Accuracy train validation= 85.67164179104478\n",
      "Param: alpha= 0.4, beta= 0.6, vigilance= 0.01\n",
      "Accuracy train validation= 81.19402985074628\n",
      "Param: alpha= 0.4, beta= 0.6, vigilance= 0.1\n",
      "Accuracy train validation= 80.59701492537313\n",
      "Param: alpha= 0.4, beta= 0.6, vigilance= 0.2\n",
      "Accuracy train validation= 83.88059701492537\n",
      "Param: alpha= 0.4, beta= 0.6, vigilance= 0.3\n",
      "Accuracy train validation= 86.56716417910448\n",
      "Param: alpha= 0.4, beta= 0.4, vigilance= 0.01\n",
      "Accuracy train validation= 82.38805970149254\n",
      "Param: alpha= 0.4, beta= 0.4, vigilance= 0.1\n",
      "Accuracy train validation= 81.19402985074628\n",
      "Param: alpha= 0.4, beta= 0.4, vigilance= 0.2\n",
      "Accuracy train validation= 81.19402985074628\n",
      "Param: alpha= 0.4, beta= 0.4, vigilance= 0.3\n",
      "Accuracy train validation= 82.68656716417911\n",
      "\n",
      "Param: alpha= 0.01, beta= 1, vigilance= 0.3\n",
      "Acuracy test= 88.49372384937239\n"
     ]
    }
   ],
   "source": [
    "for al in alpha:\n",
    "    for be in beta:\n",
    "        for vi in vigilance:\n",
    "            second_layer = run(X_train_train, y_train_train, al, be, vi)\n",
    "            acc = test(second_layer[:-1], X_train_valid, y_train_valid, al)\n",
    "            print(f\"Param: alpha= {al}, beta= {be}, vigilance= {vi}\")\n",
    "            print(f\"Accuracy train validation= {acc}\")\n",
    "            if acc > maximum_accuracy:\n",
    "                best_alpha = al\n",
    "                best_beta = be\n",
    "                best_vigilance = vi\n",
    "                maximum_accuracy = acc\n",
    "\n",
    "second_layer = run(X_train, y_train, best_alpha, best_beta, best_vigilance)\n",
    "acc = test(second_layer[:-1], X_test, y_test, best_alpha)\n",
    "print()\n",
    "print(f\"Param: alpha= {best_alpha}, beta= {best_beta}, vigilance= {best_vigilance}\")\n",
    "print(f\"Acuracy test= {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
